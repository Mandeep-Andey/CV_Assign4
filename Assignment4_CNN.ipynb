{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CS 5970/6970 Assignment 4\n",
                "**Name/Team:** [Your Name Here]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Documentation\n",
                "# This notebook is designed to run on Google Colab or a local environment.\n",
                "# If running locally, ensure you have the dependencies installed via requirements.txt.\n",
                "# If running on Colab, the next cell will install necessary packages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies for Google Colab\n",
                "!pip install torch torchvision numpy matplotlib tqdm scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "from torch.utils.data import Subset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 1: Small CNN (from scratch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CIFAR-10 dataset with Augmentation\n",
                "transform_train = transforms.Compose([\n",
                "    transforms.RandomCrop(32, padding=4),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "transform_test = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "batch_size = 4\n",
                "\n",
                "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
                "                                        download=True, transform=transform_train)\n",
                "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
                "                                          shuffle=True, num_workers=2)\n",
                "\n",
                "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
                "                                       download=True, transform=transform_test)\n",
                "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
                "                                         shuffle=False, num_workers=2)\n",
                "\n",
                "classes = ('plane', 'car', 'bird', 'cat',\n",
                "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to show an image\n",
                "def imshow(img):\n",
                "    img = img / 2 + 0.5     # unnormalize\n",
                "    npimg = img.numpy()\n",
                "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
                "    plt.show()\n",
                "\n",
                "# Get some random training images\n",
                "dataiter = iter(trainloader)\n",
                "images, labels = next(dataiter)\n",
                "\n",
                "# Show images\n",
                "imshow(torchvision.utils.make_grid(images))\n",
                "# Print labels\n",
                "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the Convolutional Neural Network\n",
                "class Net(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(Net, self).__init__()\n",
                "        # Layer 1: Conv -> BN -> ReLU -> Pool\n",
                "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
                "        self.bn1 = nn.BatchNorm2d(32)\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "\n",
                "        # Layer 2: Conv -> BN -> ReLU -> Pool\n",
                "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
                "        self.bn2 = nn.BatchNorm2d(64)\n",
                "\n",
                "        # Layer 3: Conv -> BN -> ReLU -> Pool\n",
                "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
                "        self.bn3 = nn.BatchNorm2d(128)\n",
                "\n",
                "        # Fully Connected Layers\n",
                "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
                "        self.fc2 = nn.Linear(512, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
                "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
                "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
                "        x = x.view(-1, 128 * 4 * 4)\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = self.fc2(x)\n",
                "        return x\n",
                "\n",
                "net = Net()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Summary and Parameter Count\n",
                "print(\"Model Summary:\")\n",
                "print(net)\n",
                "\n",
                "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
                "print(f\"\\nTotal Trainable Parameters: {total_params}\")\n",
                "\n",
                "if total_params > 1500000:\n",
                "    print(\"WARNING: Parameter count exceeds 1.5 million!\")\n",
                "else:\n",
                "    print(\"Parameter count is within the limit (<= 1.5M).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a Loss function and optimizer\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the network\n",
                "num_epochs = 25\n",
                "train_losses = []\n",
                "train_accs = []\n",
                "\n",
                "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
                "\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    # Use tqdm for progress bar\n",
                "    pbar = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
                "    \n",
                "    for i, data in pbar:\n",
                "        # get the inputs; data is a list of [inputs, labels]\n",
                "        inputs, labels = data\n",
                "\n",
                "        # zero the parameter gradients\n",
                "        optimizer.zero_grad()\n",
                "\n",
                "        # forward + backward + optimize\n",
                "        outputs = net(inputs)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        # print statistics\n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "        \n",
                "        # Update progress bar description\n",
                "        if i % 200 == 199:\n",
                "             pbar.set_postfix({'Loss': running_loss / (i+1), 'Acc': 100 * correct / total})\n",
                "\n",
                "    epoch_loss = running_loss / len(trainloader)\n",
                "    epoch_acc = 100 * correct / total\n",
                "    train_losses.append(epoch_loss)\n",
                "    train_accs.append(epoch_acc)\n",
                "    \n",
                "    print(f\"Epoch {epoch+1} finished. Loss: {epoch_loss:.3f}, Accuracy: {epoch_acc:.2f}%\")\n",
                "\n",
                "print('Finished Training')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Training Curves\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(train_losses, label='Training Loss')\n",
                "plt.title('Training Loss vs Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(train_accs, label='Training Accuracy')\n",
                "plt.title('Training Accuracy vs Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the network on the test data and Plot Confusion Matrix\n",
                "correct = 0\n",
                "total = 0\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data in tqdm(testloader, desc=\"Testing\"):\n",
                "        images, labels = data\n",
                "        outputs = net(images)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "        \n",
                "        all_preds.extend(predicted.numpy())\n",
                "        all_labels.extend(labels.numpy())\n",
                "\n",
                "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
                "    100 * correct / total))\n",
                "\n",
                "# Confusion Matrix\n",
                "cm = confusion_matrix(all_labels, all_preds)\n",
                "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
                "fig, ax = plt.subplots(figsize=(10, 10))\n",
                "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
                "plt.title(\"Confusion Matrix\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the model\n",
                "PATH = './cifar_net.pth'\n",
                "torch.save(net.state_dict(), PATH)\n",
                "print(f\"Model saved to {PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "**End of Task 1**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 2: Improve your CNN with Residual Connections"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Residual Block Design\n",
                "The residual block consists of two 3x3 convolutions, each followed by Batch Normalization and ReLU activation. \n",
                "A skip connection adds the input to the output of the second convolution. \n",
                "If the input and output shapes do not match (due to stride or channel changes), a 1x1 convolution is used in the skip connection to project the input to the correct shape."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Residual Block\n",
                "class ResidualBlock(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels, stride=1):\n",
                "        super(ResidualBlock, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
                "                               stride=stride, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
                "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
                "                               stride=1, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
                "\n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_channels != out_channels:\n",
                "            self.shortcut = nn.Sequential(\n",
                "                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
                "                          stride=stride, bias=False),\n",
                "                nn.BatchNorm2d(out_channels)\n",
                "            )\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.bn2(self.conv2(out))\n",
                "        out += self.shortcut(x)\n",
                "        out = F.relu(out)\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Residual CNN\n",
                "class ResidualCNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(ResidualCNN, self).__init__()\n",
                "        self.in_channels = 32\n",
                "        \n",
                "        # Initial Conv Layer\n",
                "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(32)\n",
                "        \n",
                "        # Residual Blocks\n",
                "        self.layer1 = self._make_layer(32, 32, stride=1)\n",
                "        self.layer2 = self._make_layer(32, 64, stride=2)\n",
                "        self.layer3 = self._make_layer(64, 128, stride=2)\n",
                "        \n",
                "        # Pooling to reduce size to 4x4\n",
                "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
                "        \n",
                "        # Fully Connected Layers\n",
                "        self.fc1 = nn.Linear(128 * 4 * 4, 512) \n",
                "        self.fc2 = nn.Linear(512, 10)\n",
                "\n",
                "    def _make_layer(self, in_c, out_c, stride):\n",
                "        layer = ResidualBlock(in_c, out_c, stride)\n",
                "        return layer\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.layer1(out)\n",
                "        out = self.layer2(out)\n",
                "        out = self.layer3(out)\n",
                "        out = self.avgpool(out)\n",
                "        out = out.view(out.size(0), -1)\n",
                "        out = F.relu(self.fc1(out))\n",
                "        out = self.fc2(out)\n",
                "        return out\n",
                "\n",
                "res_net = ResidualCNN()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Summary and Parameter Count for ResidualCNN\n",
                "print(\"ResidualCNN Summary:\")\n",
                "print(res_net)\n",
                "\n",
                "res_total_params = sum(p.numel() for p in res_net.parameters() if p.requires_grad)\n",
                "print(f\"\\nTotal Trainable Parameters (ResidualCNN): {res_total_params}\")\n",
                "\n",
                "if 0.8 * total_params <= res_total_params <= 1.2 * total_params:\n",
                "    print(\"Parameter count is comparable to Task 1 (within +/- 20%).\")\n",
                "else:\n",
                "    print(\"WARNING: Parameter count difference is significant.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train ResidualCNN\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer_res = optim.SGD(res_net.parameters(), lr=0.001, momentum=0.9)\n",
                "\n",
                "train_losses_res = []\n",
                "train_accs_res = []\n",
                "\n",
                "print(\"Starting training for ResidualCNN...\")\n",
                "for epoch in range(num_epochs): \n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    pbar = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc=f\"ResCNN Epoch {epoch+1}/{num_epochs}\")\n",
                "    \n",
                "    for i, data in pbar:\n",
                "        inputs, labels = data\n",
                "        optimizer_res.zero_grad()\n",
                "        outputs = res_net(inputs)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer_res.step()\n",
                "\n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "        \n",
                "        if i % 200 == 199:\n",
                "             pbar.set_postfix({'Loss': running_loss / (i+1), 'Acc': 100 * correct / total})\n",
                "\n",
                "    epoch_loss = running_loss / len(trainloader)\n",
                "    epoch_acc = 100 * correct / total\n",
                "    train_losses_res.append(epoch_loss)\n",
                "    train_accs_res.append(epoch_acc)\n",
                "    \n",
                "    print(f\"Epoch {epoch+1} finished. Loss: {epoch_loss:.3f}, Accuracy: {epoch_acc:.2f}%\")\n",
                "\n",
                "print('Finished Training ResidualCNN')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Overlay Plot: Task 1 vs Task 2\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(train_accs, label='Task 1: Simple CNN', linestyle='--')\n",
                "plt.plot(train_accs_res, label='Task 2: Residual CNN', linewidth=2)\n",
                "plt.title('Training Accuracy Comparison: Simple vs Residual CNN')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test ResidualCNN\n",
                "correct = 0\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for data in tqdm(testloader, desc=\"Testing ResCNN\"):\n",
                "        images, labels = data\n",
                "        outputs = res_net(images)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "\n",
                "print('Accuracy of the ResidualCNN on the 10000 test images: %d %%' % (\n",
                "    100 * correct / total))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparative Analysis\n",
                "\n",
                "**Optimization Stability:**\n",
                "[Your analysis here based on the loss curves. Residual networks often show smoother convergence.]\n",
                "\n",
                "**Convergence Speed:**\n",
                "[Compare how many epochs it took for each model to reach a high accuracy.]\n",
                "\n",
                "**Generalization:**\n",
                "[Compare the final test accuracy of both models. Did the residual connections help?]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "**End of Task 2**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 3: Self-Supervised Pretraining + Fine-tuning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Rotation Prediction SSL Objective\n",
                "\n",
                "In this task, we implement a self-supervised learning approach based on **Rotation Prediction**. The core idea is to train the network to predict the rotation angle applied to an input image. Each image is randomly rotated by 0째, 90째, 180째, or 270째, and the network learns to classify which rotation was applied (4-class classification). This pretext task forces the network to learn meaningful visual features without requiring labeled data, as understanding object orientation requires recognizing shapes, textures, and spatial relationships.\n",
                "\n",
                "**Augmentations:** We use `torchvision.transforms.functional.rotate()` to apply rotations and normalize the images for input to the network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rotation Dataset for SSL\n",
                "import torchvision.transforms.functional as TF\n",
                "\n",
                "class RotationDataset(torch.utils.data.Dataset):\n",
                "    def __init__(self, base_dataset):\n",
                "        self.base_dataset = base_dataset\n",
                "        self.rotations = [0, 90, 180, 270]\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.base_dataset)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img, _ = self.base_dataset[idx]  # ignore original label\n",
                "        \n",
                "        # Randomly select a rotation\n",
                "        rot_idx = np.random.randint(0, 4)\n",
                "        rotation = self.rotations[rot_idx]\n",
                "        \n",
                "        # Rotate the image\n",
                "        img_rotated = TF.rotate(img, rotation)\n",
                "        \n",
                "        return img_rotated, rot_idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create rotation dataset for SSL pretraining\n",
                "ssl_transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "ssl_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
                "                                            download=True, transform=ssl_transform)\n",
                "rotation_dataset = RotationDataset(ssl_trainset)\n",
                "ssl_trainloader = torch.utils.data.DataLoader(rotation_dataset, batch_size=64,\n",
                "                                              shuffle=True, num_workers=2)\n",
                "\n",
                "print(f\"SSL Dataset size: {len(rotation_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize ResidualCNN for SSL pretraining\n",
                "ssl_model = ResidualCNN()\n",
                "\n",
                "# Replace the final layer with a 4-class classifier for rotation prediction\n",
                "ssl_model.fc2 = nn.Linear(512, 4)\n",
                "\n",
                "print(\"SSL Model initialized with 4-class output for rotation prediction.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SSL Pretraining\n",
                "criterion_ssl = nn.CrossEntropyLoss()\n",
                "optimizer_ssl = optim.SGD(ssl_model.parameters(), lr=0.001, momentum=0.9)\n",
                "\n",
                "ssl_epochs = 10\n",
                "ssl_losses = []\n",
                "\n",
                "print(\"Starting SSL Pretraining (Rotation Prediction)...\")\n",
                "for epoch in range(ssl_epochs):\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    pbar = tqdm(ssl_trainloader, desc=f\"SSL Epoch {epoch+1}/{ssl_epochs}\")\n",
                "    \n",
                "    for data in pbar:\n",
                "        inputs, labels = data\n",
                "        \n",
                "        optimizer_ssl.zero_grad()\n",
                "        outputs = ssl_model(inputs)\n",
                "        loss = criterion_ssl(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer_ssl.step()\n",
                "        \n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "    \n",
                "    epoch_loss = running_loss / len(ssl_trainloader)\n",
                "    epoch_acc = 100 * correct / total\n",
                "    ssl_losses.append(epoch_loss)\n",
                "    \n",
                "    print(f\"SSL Epoch {epoch+1} finished. Loss: {epoch_loss:.3f}, Acc: {epoch_acc:.2f}%\")\n",
                "\n",
                "print('Finished SSL Pretraining')\n",
                "\n",
                "# Save pretrained weights\n",
                "torch.save(ssl_model.state_dict(), './ssl_pretrained.pth')\n",
                "print(\"Pretrained weights saved to ssl_pretrained.pth\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot SSL Training Loss\n",
                "plt.figure(figsize=(8, 5))\n",
                "plt.plot(ssl_losses, label='SSL Pretraining Loss', marker='o')\n",
                "plt.title('SSL Pretraining Loss vs Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create 10% subset of CIFAR-10 (balanced across classes)\n",
                "def get_balanced_subset_indices(dataset, ratio=0.1):\n",
                "    # Get all labels\n",
                "    labels = np.array(dataset.targets)\n",
                "    num_classes = 10\n",
                "    samples_per_class = int(len(dataset) * ratio / num_classes)\n",
                "    \n",
                "    indices = []\n",
                "    for class_idx in range(num_classes):\n",
                "        class_indices = np.where(labels == class_idx)[0]\n",
                "        selected = np.random.choice(class_indices, samples_per_class, replace=False)\n",
                "        indices.extend(selected)\n",
                "    \n",
                "    return indices\n",
                "\n",
                "subset_indices = get_balanced_subset_indices(trainset, ratio=0.1)\n",
                "subset_trainset = Subset(trainset, subset_indices)\n",
                "subset_trainloader = torch.utils.data.DataLoader(subset_trainset, batch_size=4,\n",
                "                                                  shuffle=True, num_workers=2)\n",
                "\n",
                "print(f\"10% Subset size: {len(subset_trainset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained model and reset classification head\n",
                "finetuned_model = ResidualCNN()\n",
                "finetuned_model.load_state_dict(torch.load('./ssl_pretrained.pth'))\n",
                "\n",
                "# Reset final layer for 10-class classification\n",
                "finetuned_model.fc2 = nn.Linear(512, 10)\n",
                "\n",
                "print(\"Loaded pretrained weights. Reset classification head to 10 classes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fine-tuning on 10% data\n",
                "criterion_ft = nn.CrossEntropyLoss()\n",
                "optimizer_ft = optim.SGD(finetuned_model.parameters(), lr=0.001, momentum=0.9)\n",
                "\n",
                "ft_epochs = 20\n",
                "ft_losses = []\n",
                "ft_accs = []\n",
                "\n",
                "print(\"Starting Fine-tuning on 10% labeled data...\")\n",
                "for epoch in range(ft_epochs):\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    pbar = tqdm(subset_trainloader, desc=f\"FT Epoch {epoch+1}/{ft_epochs}\")\n",
                "    \n",
                "    for data in pbar:\n",
                "        inputs, labels = data\n",
                "        \n",
                "        optimizer_ft.zero_grad()\n",
                "        outputs = finetuned_model(inputs)\n",
                "        loss = criterion_ft(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer_ft.step()\n",
                "        \n",
                "        running_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "    \n",
                "    epoch_loss = running_loss / len(subset_trainloader)\n",
                "    epoch_acc = 100 * correct / total\n",
                "    ft_losses.append(epoch_loss)\n",
                "    ft_accs.append(epoch_acc)\n",
                "    \n",
                "    print(f\"FT Epoch {epoch+1} finished. Loss: {epoch_loss:.3f}, Acc: {epoch_acc:.2f}%\")\n",
                "\n",
                "print('Finished Fine-tuning')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Fine-tuning Training Curves\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(ft_losses, label='Fine-tuning Loss', marker='o')\n",
                "plt.title('Fine-tuning Loss vs Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(ft_accs, label='Fine-tuning Accuracy', marker='o', color='green')\n",
                "plt.title('Fine-tuning Accuracy vs Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Fine-tuned Model\n",
                "correct = 0\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for data in tqdm(testloader, desc=\"Testing Fine-tuned Model\"):\n",
                "        images, labels = data\n",
                "        outputs = finetuned_model(images)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        total += labels.size(0)\n",
                "        correct += (predicted == labels).sum().item()\n",
                "\n",
                "ft_test_acc = 100 * correct / total\n",
                "print('Accuracy of the Fine-tuned Model on the 10000 test images: %d %%' % ft_test_acc)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Discussion: Did SSL Help?\n",
                "\n",
                "**Impact of SSL Pretraining:**\n",
                "[Analyze whether the SSL pretraining helped achieve higher accuracy or faster convergence compared to training from scratch on the 10% data. Consider factors like final test accuracy and the shape of the training curves.]\n",
                "\n",
                "**Observations:**\n",
                "- SSL pretraining should provide a better initialization than random weights.\n",
                "- The fine-tuned model may converge faster and achieve higher accuracy with limited labeled data.\n",
                "- Compare the final test accuracy with the baseline Task 2 model trained on full data to understand the effectiveness of SSL."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "**End of Task 3**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
